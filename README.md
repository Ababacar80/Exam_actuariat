# ğŸ¥ Exam Actuariat - PrÃ©diction de Sinistres d'Assurance

Un package Python pour la prÃ©diction de sinistres dans le domaine de l'assurance santÃ©, dÃ©veloppÃ© dans le cadre d'un examen actuariel.

## ğŸ¯ Objectif

Ce projet vise Ã  dÃ©velopper des modÃ¨les de machine learning pour prÃ©dire les montants de sinistres dans l'assurance santÃ© en utilisant des donnÃ©es dÃ©mographiques et de santÃ©.

## ğŸ“‹ FonctionnalitÃ©s

- **Chargement de donnÃ©es** : Support des fichiers Excel et CSV
- **Preprocessing** : Nettoyage, encodage et normalisation des donnÃ©es
- **Analyse exploratoire** : CorrÃ©lations, statistiques descriptives et dÃ©tection d'outliers
- **Visualisation** : Graphiques interactifs et heatmaps
- **ModÃ©lisation** : Algorithmes de boosting avancÃ©s (XGBoost, LightGBM)
- **Ã‰valuation** : MÃ©triques complÃ¨tes et validation croisÃ©e

## ğŸ”§ Installation

### PrÃ©requis
- Python 3.11 ou supÃ©rieur
- Poetry (recommandÃ©) ou pip

### Installation avec Poetry
```bash
# Cloner le repository
git clone <url-du-repo>
cd exam-actuariat

# Installer les dÃ©pendances
poetry install

# Activer l'environnement virtuel
poetry shell
```

### Installation avec pip
```bash
# Cloner le repository
git clone <url-du-repo>
cd exam-actuariat

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Installer les dÃ©pendances
pip install -e .
```

### DÃ©pendances optionnelles
```bash
# Pour le dÃ©veloppement
poetry install --extras dev

# Pour la documentation
poetry install --extras docs

# Installer les algorithmes de boosting
pip install xgboost lightgbm
```

## ğŸ“ Structure du Projet

```
exam-actuariat/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ exam_actuariat/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ data_loading.py      # Chargement des donnÃ©es
â”‚       â”œâ”€â”€ data_processing.py   # Preprocessing
â”‚       â”œâ”€â”€ exploration.py       # Analyse exploratoire
â”‚       â”œâ”€â”€ features.py         # Extraction de features
â”‚       â”œâ”€â”€ visualization.py    # Visualisations
â”‚       â”œâ”€â”€ models.py          # ModÃ¨les ML
â”‚       â””â”€â”€ evaluation.py     # Ã‰valuation
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ train.py              # Script d'entraÃ®nement
â”œâ”€â”€ data/
â”‚   â””â”€â”€                   # DonnÃ©es brutes
â”œâ”€â”€ models/                   # ModÃ¨les sauvegardÃ©s
â”œâ”€â”€ tests/                    # Tests unitaires
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

## ğŸš€ Utilisation

### 1. PrÃ©parer les donnÃ©es
Placez le fichier de donnÃ©es dans `data/`. 

### 2. ExÃ©cuter l'analyse complÃ¨te
```bash
python scripts/train.py
```

### 3. Utilisation programmatique
```python
from src.exam_actuariat import data_loading, data_processing, models, features

# Charger les donnÃ©es
df = data_loading.load_raw('data/insurance-demographic-health.csv')

# Preprocessing
df_clean = data_processing.clean_data(df)
df_encoded = data_processing.encodage(df_clean)

# Analyse des features
feature_importances = features.get_feature_importance(df_encoded, target='claim')
print(feature_importances.head())

# EntraÃ®ner un modÃ¨le
from sklearn.model_selection import train_test_split
X = df_encoded.drop(columns=['claim'])
y = df_encoded['claim']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

model = models.train_xgboost(X_train, y_train)
results = models.evaluate_model(model, X_test, y_test)
print(results)
```

## ğŸ“Š Modules Disponibles

### `data_loading`
- `load_raw(filepath)` : Charge les donnÃ©es depuis un fichier Excel/CSV

### `data_processing`
- `clean_data(df)` : Nettoie les donnÃ©es (supprime doublons et valeurs manquantes)
- `encodage(df)` : Encode les variables catÃ©gorielles
- `scale_features(df)` : Normalise les features numÃ©riques
- `apply_smote(X, y)` : Applique SMOTE pour l'Ã©quilibrage des classes

### `exploration`
- `analyze_correlation(df)` : Calcule les corrÃ©lations
- `analyze_by_gender(df)` : Statistiques par genre
- `analyze_smoking_impact(df)` : Impact du tabagisme
- `detect_outliers(df, column)` : DÃ©tection d'outliers

### `features`
- `get_feature_importance(df, target)` : Calcule l'importance des variables avec Random Forest

### `models`
- `train_xgboost(X, y)` : EntraÃ®ne un modÃ¨le XGBoost
- `train_lightgbm(X, y)` : EntraÃ®ne un modÃ¨le LightGBM
- `train_linear_regression(X, y)` : EntraÃ®ne une rÃ©gression linÃ©aire
- `evaluate_model(model, X, y)` : Ã‰value un modÃ¨le
- `save_model(model, filepath)` : Sauvegarde un modÃ¨le
- `load_model(filepath)` : Charge un modÃ¨le

### `evaluation`
- `compare_models(results)` : Compare plusieurs modÃ¨les
- `cross_validate_model(model, X, y)` : Validation croisÃ©e
- `plot_predictions_vs_actual(y_true, y_pred)` : Visualise les prÃ©dictions

## ğŸ§ª Tests

```bash
# ExÃ©cuter tous les tests
pytest

# Avec couverture de code
pytest --cov=src/exam_actuariat
```

## ğŸ“ˆ MÃ©triques d'Ã‰valuation

Le projet utilise plusieurs mÃ©triques pour Ã©valuer les modÃ¨les :
- **MAE** (Mean Absolute Error) : Erreur absolue moyenne
- **MSE** (Mean Squared Error) : Erreur quadratique moyenne
- **RMSE** (Root Mean Squared Error) : Racine de l'erreur quadratique moyenne
- **RÂ²** (Coefficient de dÃ©termination) : Variance expliquÃ©e
- **MAPE** (Mean Absolute Percentage Error) : Erreur absolue en pourcentage

## ğŸ”§ Configuration

Les paramÃ¨tres des modÃ¨les peuvent Ãªtre ajustÃ©s dans le script `train.py` ou passÃ©s directement aux fonctions d'entraÃ®nement :

```python
# Exemple de configuration XGBoost
model = models.train_xgboost(
    X_train, y_train,
    n_estimators=200,
    max_depth=8,
    learning_rate=0.05
)
```

## âš¡ Algorithmes SupportÃ©s

### XGBoost (Extreme Gradient Boosting)
- **Avantages** : TrÃ¨s performant, gestion des interactions non-linÃ©aires
- **Usage** : Champion des compÃ©titions Kaggle
- **Installation** : `poetry add xgboost`

### LightGBM (Light Gradient Boosting Machine)
- **Avantages** : Rapide, efficace en mÃ©moire
- **Usage** : Optimal pour les gros datasets
- **Installation** : `poetry add lightgbm`

### RÃ©gression LinÃ©aire
- **Avantages** : Simple, interprÃ©table
- **Usage** : Baseline et comparaison

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©er une branche pour votre feature (`git checkout -b feature/AmazingFeature`)
3. Commit vos changements (`git commit -m 'Add some AmazingFeature'`)
4. Push sur la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

## ğŸ‘¨â€ğŸ’» Auteur

**Ababacar Sagna**
- Email: ababacarsagna10@gmail.com

## ğŸ› ProblÃ¨mes Connus

- XGBoost et LightGBM doivent Ãªtre installÃ©s sÃ©parÃ©ment
- Les visualisations nÃ©cessitent un environnement graphique

## ğŸ“š Documentation

Pour plus de dÃ©tails sur l'utilisation des modules, consultez les docstrings dans le code ou gÃ©nÃ©rez la documentation :

```bash
# Installer les dÃ©pendances de documentation
poetry install --extras docs

# GÃ©nÃ©rer la documentation
cd docs
make html
```