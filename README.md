# ğŸ¥ PrÃ©diction de Sinistres d'Assurance

Un package Python pour la prÃ©diction de sinistres dans le domaine de l'assurance santÃ©, dÃ©veloppÃ© dans le cadre d'un examen actuariel.

## ğŸ¯ Objectif

Ce projet vise Ã  dÃ©velopper des modÃ¨les de machine learning pour prÃ©dire les montants de sinistres dans l'assurance santÃ© en utilisant des donnÃ©es dÃ©mographiques et de santÃ©.

## ğŸ“‹ FonctionnalitÃ©s

- **Chargement de donnÃ©es** : Support des fichiers CSV
- **Preprocessing** : Nettoyage et encodage des donnÃ©es
- **Analyse exploratoire** : CorrÃ©lations, statistiques descriptives par genre et impact du tabagisme
- **ModÃ©lisation** : Algorithmes de boosting avancÃ©s (XGBoost, LightGBM)
- **Ã‰valuation** : MÃ©triques complÃ¨tes et validation croisÃ©e


## ğŸ“ Structure du Projet

```
exam-actuariat/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ exam_actuariat/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ data_loading.py      # Chargement des donnÃ©es
â”‚       â”œâ”€â”€ data_processing.py   # Preprocessing
â”‚       â”œâ”€â”€ exploration.py       # Analyse exploratoire
â”‚       â”œâ”€â”€ features.py         # Extraction de features
â”‚       â”œâ”€â”€ models.py          # ModÃ¨les ML
â”‚       â””â”€â”€ evaluation.py     # Ã‰valuation
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ train.py              # Script d'entraÃ®nement
â”œâ”€â”€ data/
â”‚   â””â”€â”€                   # DonnÃ©es brutes
â”œâ”€â”€ models/                   # ModÃ¨les sauvegardÃ©s
â”œâ”€â”€ tests/                    # Tests unitaires
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

## ğŸš€ Utilisation

### 1. PrÃ©parer les donnÃ©es
Placez le fichier de donnÃ©es CSV dans `data/`. 

### 2. ExÃ©cuter l'analyse complÃ¨te
```bash
python scripts/train.py
```

### 3. Utilisation programmatique
```python
from src.exam_actuariat import data_loading, data_processing, models, features
from sklearn.model_selection import train_test_split

# Charger les donnÃ©es
df = data_loading.load_raw('data/insurance-demographic-health.csv')

# Preprocessing
df_clean = data_processing.clean_data(df)
df_encoded = data_processing.encodage(df_clean)

# PrÃ©parer les donnÃ©es
X = df_encoded.drop(columns=['claim'])
y = df_encoded['claim']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Analyse des features
feature_importances = features.get_feature_importance(X_train, y_train)
print(feature_importances.head())

# EntraÃ®ner un modÃ¨le
model = models.train_xgboost(X_train, y_train)
results = models.evaluate_model(model, X_test, y_test, model_name='XGBoost')
print(f"MAE: {results['mae']:.2f}, RÂ²: {results['r2']:.3f}")
```

## ğŸ“Š Modules Disponibles

### `data_loading`
- `load_raw(filepath)` : Charge les donnÃ©es depuis un fichier CSV

### `data_processing`
- `clean_data(df)` : Nettoie les donnÃ©es (supprime doublons et valeurs manquantes)
- `encodage(df)` : Encode les variables catÃ©gorielles

### `exploration`
- `analyze_correlation(df)` : Calcule les corrÃ©lations
- `analyze_by_gender(df)` : Statistiques par genre
- `analyze_smoking_impact(df)` : Impact du tabagisme

### `features`
- `get_feature_importance(X, y)` : Calcule l'importance des variables avec Random Forest

### `models`
- `train_xgboost(X_train, y_train)` : EntraÃ®ne un modÃ¨le XGBoost
- `train_lightgbm(X_train, y_train)` : EntraÃ®ne un modÃ¨le LightGBM
- `evaluate_model(model, X_test, y_test, model_name)` : Ã‰value un modÃ¨le
- `save_model(model, filepath)` : Sauvegarde un modÃ¨le

### `evaluation`
- `compare_models(results_list)` : Compare plusieurs modÃ¨les
- `cross_validate_model(model, X, y, cv)` : Validation croisÃ©e

## ğŸ§ª Tests

```bash
# ExÃ©cuter tous les tests
pytest tests/test_simple.py

# Tests basiques uniquement
pytest tests/test_simple.py::test_basic_python
```

## ğŸ“ˆ MÃ©triques d'Ã‰valuation

Le projet utilise plusieurs mÃ©triques pour Ã©valuer les modÃ¨les :
- **MAE** (Mean Absolute Error) : Erreur absolue moyenne
- **MSE** (Mean Squared Error) : Erreur quadratique moyenne
- **RMSE** (Root Mean Squared Error) : Racine de l'erreur quadratique moyenne
- **RÂ²** (Coefficient de dÃ©termination) : Variance expliquÃ©e

## ğŸ”§ Configuration

Les paramÃ¨tres des modÃ¨les peuvent Ãªtre ajustÃ©s directement aux fonctions d'entraÃ®nement :

```python
# Exemple de configuration XGBoost
model = models.train_xgboost(
    X_train, y_train,
    n_estimators=200,
    max_depth=8,
    learning_rate=0.05
)
```

## âš¡ Algorithmes SupportÃ©s

### XGBoost (Extreme Gradient Boosting)
- **Avantages** : TrÃ¨s performant, gestion des interactions non-linÃ©aires
- **Usage** : Champion des compÃ©titions Kaggle
- **Installation** : `pip install xgboost`

### LightGBM (Light Gradient Boosting Machine)
- **Avantages** : Rapide, efficace en mÃ©moire
- **Usage** : Optimal pour les gros datasets
- **Installation** : `pip install lightgbm`

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©er une branche pour votre feature (`git checkout -b feature/AmazingFeature`)
3. Commit vos changements (`git commit -m 'Add some AmazingFeature'`)
4. Push sur la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

## ğŸ‘¨â€ğŸ’» Auteur

**Ababacar Sagna**
- Email: ababacarsagna10@gmail.com

## ğŸ› ProblÃ¨mes Connus

- XGBoost et LightGBM doivent Ãªtre installÃ©s sÃ©parÃ©ment
- Le fichier de donnÃ©es doit Ãªtre au format CSV

## ğŸ“š Documentation

Pour plus de dÃ©tails sur l'utilisation des modules, consultez les docstrings dans le code.

## ğŸ—ƒï¸ Pipeline d'Analyse

Le script `train.py` exÃ©cute automatiquement :

1. **Chargement** des donnÃ©es CSV
2. **Nettoyage** (suppression doublons/NaN)
3. **Analyse exploratoire** (corrÃ©lations, statistiques par genre, impact tabagisme)
4. **Encodage** des variables catÃ©gorielles
5. **Split** train/test (80/20)
6. **Calcul** de l'importance des features
7. **EntraÃ®nement** des modÃ¨les (XGBoost, LightGBM)
8. **Ã‰valuation** et comparaison
9. **Validation croisÃ©e** du meilleur modÃ¨le
10. **Sauvegarde** du modÃ¨le optimal

## ğŸ“Š Exemple de Sortie

```
Chargement des donnÃ©es...
DonnÃ©es chargÃ©es: (1340, 11)
Nettoyage des donnÃ©es...
DonnÃ©es nettoyÃ©es: (1332, 11)

Analyse des corrÃ©lations...
age_claim: -0.029
bmi_claim: 0.200
bloodpressure_claim: 0.531
children_claim: 0.064

Analyse par genre...
Statistiques par genre:
        count          mean           std      min        25%       50%        75%       max
gender                                                                                      
female  662.0  12569.578897  11128.703817  1607.51  4885.1625  9412.965  14454.690  63770.43
male    670.0  14071.891060  12971.546624  1121.87  4676.6400  9439.495  19160.175  62592.87

Analyse de l'impact du tabagisme...
Smoking Impact Analysis
Mean Claim Amount for Smokers: 32050.23
Mean Claim Amount for Non-Smokers: 8475.86
Correlation tabagisme: 0.787

Encodage des variables...
PrÃ©paration des donnÃ©es...
Train: (1065, 10), Test: (267, 10)

Calcul de l'importance des features...
Top 5 features:
bloodpressure    0.350
smoker           0.285
bmi              0.180
age              0.125
children         0.060

EntraÃ®nement des modÃ¨les...
EntraÃ®nement XGBoost...
EntraÃ®nement LightGBM...

RÃ©sultats de comparaison:
  model_name         mae        rmse        r2
0    XGBoost  2845.67  4205.23  0.885
1   LightGBM  3102.14  4598.45  0.863

Validation croisÃ©e pour le meilleur modÃ¨le: XGBoost
XGBoost Cross-Validation MAE: 2967.42 Â± 245.18

==================================================
ANALYSE TERMINÃ‰E AVEC SUCCÃˆS !
Meilleur modÃ¨le: XGBoost
MAE: 2845.67
RÂ²: 0.885
==================================================
```
